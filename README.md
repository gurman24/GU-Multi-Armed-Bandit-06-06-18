## Multi-Armed Bandit ##

In this project, we will examine the classic reinforcement learning problem known as the Multi-Armed Bandit. It is also known as the K-armed bandit problem or the N-armed bandit problem [1, see footnotes in the end]. Here, we are looking to maximize our potential gains from a set of potential resources by choosing between each resource so as to maximize our expected gains. (The term I've heard the most here is "maximize our rewards" and that entails knowing how much rewards, if any, might be derived from a set of actions). This kind of problem has been researched since the 1950's and may take many forms including: A) how to distribute a given budget among these research departments to maximize results? B) gaining the most out of clinical trials while minimizing potential losses, C) financial applications, etc [1]. In this case, we will start with the simplest example: slot machines.


![one_arm_bandit](https://user-images.githubusercontent.com/22970879/41629289-ec662a58-73e5-11e8-9f41-40c6d7ba5a36.jpg)


Please be aware that we will be choosing between different resources through the use of an AGENT. Meaning, an algorithm or a program that we have trained to make decisions that will then work on its own. 




optimal policy for maximizing the expected discounted reward



1 = https://en.wikipedia.org/wiki/Multi-armed_bandit 

2 = http://blog.yhat.com/posts/the-beer-bandit.html 

3 = https://jamesmccaffrey.wordpress.com/2017/11/30/the-epsilon-greedy-algorithm/





